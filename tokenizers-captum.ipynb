{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hugging Face \"Tokenizers\"와 PyTorch \"Captum\" 라이브러리 사용기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 추출 및 훈련 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# NSMC 훈련용 코퍼스 내 문장 및 라벨 데이터 추출\n",
    "\n",
    "f_train = pd.read_csv('data/ratings_train.txt', sep='\\t')\n",
    "train_pair = [(row[1], row[2]) for _, row in f_train.iterrows() if type(row[1]) == str]\n",
    "\n",
    "train_data  = [pair[0] for pair in train_pair]\n",
    "train_label = [pair[1] for pair in train_pair]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장: 아 더빙.. 진짜 짜증나네요 목소리\n",
      "라벨: 0\n",
      "\n",
      "문장: 흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\n",
      "라벨: 1\n",
      "\n",
      "문장: 너무재밓었다그래서보는것을추천한다\n",
      "라벨: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 추출된 문장 및 라벨 데이터 일부 확인\n",
    "\n",
    "for data, label in zip(train_data[:3], train_label[:3]):\n",
    "    print(f'문장: {data}\\n라벨: {label}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizers 라이브러리 활용한 토크나이저 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프로젝트 전반에 사용될 변수 사전 정의\n",
    "\n",
    "params = {\n",
    "    'batch_size': 64,\n",
    "    'num_epoch': 10,\n",
    "    'lr': 0.003,\n",
    "    'dropout': 0.5,\n",
    "    'min_frequency': 3,\n",
    "    'max_len': 20,\n",
    "    \n",
    "    'vocab_size': 20000,\n",
    "    'embed_dim': 100,\n",
    "    'hidden_dim': 256,\n",
    "    'filter_sizes': [2, 3, 4],\n",
    "    'num_filters': 100,\n",
    "    'output_dim': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추출한 문장 데이터 텍스트 파일로 저장\n",
    "\n",
    "with open('train_tokenizer.txt', 'w', encoding='utf-8') as f:\n",
    "    for line in train_data:\n",
    "        print(line, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import BPETokenizer\n",
    "\n",
    "# BPE 토크나이저 초기화\n",
    "\n",
    "tokenizer = BPETokenizer()\n",
    "\n",
    "\n",
    "# 앞서 제작한 텍스트 파일 활용해 토크나이저 훈련\n",
    "\n",
    "tokenizer.train(\n",
    "    'train_tokenizer.txt',\n",
    "    vocab_size=params['vocab_size'],\n",
    "    min_frequency=params['min_frequency'],\n",
    "    suffix='',\n",
    "    special_tokens=['<PAD>', '<SOS>', '<EOS>', '<UNK>'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# 패딩 토큰 인덱스 확인\n",
    "\n",
    "print(tokenizer.token_to_id('<PAD>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스페셜 토큰 변수화\n",
    "\n",
    "pad_idx = tokenizer.token_to_id('<PAD>')\n",
    "sos_idx = tokenizer.token_to_id('<SOS>')\n",
    "eos_idx = tokenizer.token_to_id('<EOS>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토크나이저에 대해 패딩 옵션 설정\n",
    "\n",
    "tokenizer.enable_padding(pad_id=pad_idx, pad_token='<PAD>', max_length=params['max_len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'encode_batch' 함수 이용해 훈련 데이터셋에 대해 토크나이즈 수행\n",
    "\n",
    "encoded_data = tokenizer.encode_batch(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터:\t149995 개\n",
      "훈련 라벨:\t149995 개\n",
      "인코딩 데이터:\t149995 개\n"
     ]
    }
   ],
   "source": [
    "# 데이터 개수 확인\n",
    "\n",
    "print(f'훈련 데이터:\\t{len(train_data)} 개')\n",
    "print(f'훈련 라벨:\\t{len(train_label)} 개')\n",
    "print(f'인코딩 데이터:\\t{len(encoded_data)} 개')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토큰: ['20', '여', '년이', '흘러', '두', '기억에', '남는', '사랑에', '대해', '생각해', '볼수있는', '유쾌한', '영화', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "\n",
      "아이디: [1216, 647, 1958, 2402, 291, 1665, 1310, 2877, 1827, 2162, 3922, 2863, 1005, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# 토크나이저 초기 훈련 결과 확인\n",
    "\n",
    "print(f'토큰: {encoded_data[2020].tokens}\\n')\n",
    "print(f'아이디: {encoded_data[2020].ids}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 토크나이즈 결과 후처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 사전 구축\n",
    "\n",
    "vocab = {}\n",
    "\n",
    "for idx in range(20000):\n",
    "    word = tokenizer.id_to_token(idx)\n",
    "    id = tokenizer.token_to_id(word)\n",
    "    vocab[word] = id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 후처리 함수 정의\n",
    "\n",
    "def postprocess(input_ids):\n",
    "    input_ids = [sos_idx] + input_ids\n",
    "    \n",
    "    # 문장 최대 길이까지 슬라이싱\n",
    "    input_ids = input_ids[:params['max_len']]\n",
    "\n",
    "    # 패딩 토큰이 포함된 문장이라면 원 문장 말미에 <EOS> 토큰 삽입 \n",
    "    if pad_idx in input_ids:\n",
    "        pad_start = input_ids.index(pad_idx)\n",
    "        input_ids[pad_start] = eos_idx\n",
    "\n",
    "    # 패딩 토큰이 포함되지 않은 문장이라면, 시퀀스 말미에 <EOS> 토큰 삽입\n",
    "    else:\n",
    "        input_ids[-1] = eos_idx\n",
    "    \n",
    "    return input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 후처리 함수 이용해 토크나이즈 문장 후처리\n",
    "\n",
    "processed_data = [postprocess(data.ids) for data in encoded_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "후처리 결과: [1, 1216, 647, 1958, 2402, 291, 1665, 1310, 2877, 1827, 2162, 3922, 2863, 1005, 2, 0, 0, 0, 0, 0]\n",
      "\n",
      "후처리 결과 디코딩: <SOS>20여년이흘러두기억에남는사랑에대해생각해볼수있는유쾌한영화<EOS><PAD><PAD><PAD><PAD><PAD>\n"
     ]
    }
   ],
   "source": [
    "# 후처리 결과 확인\n",
    "\n",
    "print(f'후처리 결과: {processed_data[2020]}\\n')\n",
    "print(f'후처리 결과 디코딩: {tokenizer.decode(processed_data[2020])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 간단한 CNN 문장 분류기 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils import data\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 모델 정의\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(params['vocab_size'], params['embed_dim'], padding_idx=pad_idx)\n",
    "\n",
    "        self.convs = nn.ModuleList([nn.Conv2d(in_channels=1, \n",
    "                                              out_channels=params['num_filters'], \n",
    "                                              kernel_size=(fs, params['embed_dim'])) \n",
    "                                    for fs in params['filter_sizes']])\n",
    "        \n",
    "        self.fc = nn.Linear(len(params['filter_sizes']) * params['num_filters'], 1)\n",
    "        \n",
    "        self.dropout = nn.Dropout(params['dropout'])\n",
    "        \n",
    "    def forward(self, input_ids):\n",
    "        # input_ids = [배치 사이즈, 문장 길이]\n",
    "\n",
    "        embedded = self.embedding(input_ids).unsqueeze(1)\n",
    "        # embedded = [배치 사이즈, 채널 개수, 임베딩 차원]\n",
    "        \n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "        # conved_n = [배치 사이즈, 필터 개수, 문장 길이 - 필터 리스트[n] + 1]\n",
    "        \n",
    "        max_pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        # max_pooled_n = [배치 사이즈, 필터 개수]\n",
    "\n",
    "        cat = self.dropout(torch.cat(max_pooled, dim = 1))\n",
    "        # cat = [배치 사이즈, 필터 개수 x len(필터 리스트)]\n",
    "\n",
    "        return self.fc(cat)  # [배치 사이즈, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 텐서 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 및 라벨 데이터 torch Tensor로 변환\n",
    "\n",
    "processed_data = [torch.LongTensor(data).to(device) for data in processed_data]\n",
    "train_label = [torch.FloatTensor([label]).to(device) for label in train_label]\n",
    "\n",
    "\n",
    "# torch Tensor로 변환한 데이터 이용해 Iterator 정의\n",
    "\n",
    "train_iter = data.DataLoader(processed_data, batch_size=params['batch_size'])\n",
    "label_iter = data.DataLoader(train_label, batch_size=params['batch_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 이용해 CNN 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Train Loss: 0.466\n",
      "Epoch: 02 | Train Loss: 0.345\n",
      "Epoch: 03 | Train Loss: 0.304\n",
      "Epoch: 04 | Train Loss: 0.274\n",
      "Epoch: 05 | Train Loss: 0.243\n",
      "Epoch: 06 | Train Loss: 0.211\n",
      "Epoch: 07 | Train Loss: 0.180\n",
      "Epoch: 08 | Train Loss: 0.161\n",
      "Epoch: 09 | Train Loss: 0.146\n",
      "Epoch: 10 | Train Loss: 0.137\n"
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "criterion.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=params['lr'])\n",
    "\n",
    "for epoch in range(params['num_epoch']):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for (batch, label) in zip(train_iter, label_iter):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = model(batch).squeeze(1)    # [배치 사이즈]\n",
    "        labels = label.view(label.size(0))  # [배치 사이즈]\n",
    "\n",
    "        loss = criterion(logits, labels)\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    train_loss = epoch_loss / len(train_iter)        \n",
    "    print(f'Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Captum을 이용한 모델 해석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 해석에 필요한 Captum API 임포트 및 정의\n",
    "\n",
    "from captum.attr import LayerIntegratedGradients, TokenReferenceBase, visualization\n",
    "\n",
    "token_reference = TokenReferenceBase(reference_token_idx=pad_idx)  # 레퍼런스 생성 위한 모듈\n",
    "lig = LayerIntegratedGradients(model, model.embedding)             # 결과 해석에 사용되는 IntegratedGradient 기법 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_data_records_ig = []\n",
    "\n",
    "label_vocab  = {0: '부정', 1: '긍정'}\n",
    "\n",
    "def interpret_sentence(model, sentence, label = 0):       \n",
    "    model.zero_grad()\n",
    "    \n",
    "    input_ids = tokenizer.encode(sentence)\n",
    "    input_tokens = input_ids.tokens[:params['max_len']]\n",
    "    \n",
    "    input_ids = postprocess(input_ids.ids)\n",
    "    input_indices_tensor = torch.LongTensor(input_ids).to(device).unsqueeze(0)\n",
    "\n",
    "    # 단일 문장에 대한 예측 작업 수행\n",
    "    pred = torch.sigmoid(model(input_indices_tensor)).item()\n",
    "    pred_ind = round(pred)\n",
    "\n",
    "    # 베이스 라인 역할을 할 Reference 생성: 주로 패딩 토큰으로 채워줌\n",
    "    reference_indices = token_reference.generate_reference(params['max_len'], device=device).unsqueeze(0)\n",
    "\n",
    "    # LayerIntegratedGradients 모듈 활용해 개별 단어의 속성값 및 델타값 근사치 계산\n",
    "    attributions_ig, delta = lig.attribute(input_indices_tensor, reference_indices, n_steps=500, return_convergence_delta=True)\n",
    "\n",
    "    print('pred: ', label_vocab[pred_ind], '(', '%.2f'%pred, ')', ', delta: ', abs(delta))\n",
    "\n",
    "    add_attributions_to_visualizer(attributions_ig, input_tokens, pred, pred_ind, label, delta, vis_data_records_ig)\n",
    "    \n",
    "\n",
    "def add_attributions_to_visualizer(attributions, text, pred, pred_ind, label, delta, vis_data_records):\n",
    "    attributions = attributions.sum(dim=2).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "    attributions = attributions.cpu().detach().numpy()\n",
    "\n",
    "    # 시각화 위해 샘플을 리스트에 추가\n",
    "    vis_data_records.append(visualization.\n",
    "                                VisualizationDataRecord(\n",
    "                                    attributions,\n",
    "                                    pred,\n",
    "                                    label_vocab[pred_ind],\n",
    "                                    label_vocab[label],\n",
    "                                    label_vocab[1],\n",
    "                                    attributions.sum(),       \n",
    "                                    text,\n",
    "                                delta\n",
    "                                )\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  긍정 ( 1.00 ) , delta:  tensor([1.2773], device='cuda:0')\n",
      "pred:  부정 ( 0.00 ) , delta:  tensor([1.0413], device='cuda:0')\n",
      "pred:  긍정 ( 1.00 ) , delta:  tensor([4.3315], device='cuda:0')\n",
      "pred:  부정 ( 0.00 ) , delta:  tensor([2.3641], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# 예제 문장 추가 및 분석 수행\n",
    "\n",
    "interpret_sentence(model, '보면후회하지않을 영화였다 아쉬운부분이 없었고 마지막까지 긴장감있었다', label=1)\n",
    "interpret_sentence(model, '평이 워낙 좋아 갔는데 거품이 심한듯.. 개연성도 엉망에 르부아 블랑의 뜬금없는 직관에만 의존한 스토리 전개 ;; 평점 거품이 심한듯', label=0)\n",
    "interpret_sentence(model, '너무 재미있게 봤습니다. 클래식한 추리소설 느낌.타 인기영화때문에 개봉관이 적어 아쉽네요', label=1)\n",
    "interpret_sentence(model, '아, 2시간 넘게 지루하고 어이없는 추격전과 의욕이 넘쳐 과욕으로 변한 연기, 게다가 예상보다 너무 뻔한 결말로 고문당함.', label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table width: 100%><tr><th>Target Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>긍정</b></text></td><td><text style=\"padding-right:2em\"><b>긍정 (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>긍정</b></text></td><td><text style=\"padding-right:2em\"><b>1.31</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 보면                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 후회하지                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 않을                    </font></mark><mark style=\"background-color: hsl(120, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 영화였다                    </font></mark><mark style=\"background-color: hsl(120, 75%, 83%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 아쉬운                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 부분이                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 없었고                    </font></mark><mark style=\"background-color: hsl(0, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 마지막까지                    </font></mark><mark style=\"background-color: hsl(120, 75%, 62%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 긴장감                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 있었다                    </font></mark><mark style=\"background-color: hsl(120, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #PAD                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #PAD                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #PAD                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #PAD                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #PAD                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #PAD                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #PAD                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #PAD                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #PAD                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #PAD                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>부정</b></text></td><td><text style=\"padding-right:2em\"><b>부정 (0.00)</b></text></td><td><text style=\"padding-right:2em\"><b>긍정</b></text></td><td><text style=\"padding-right:2em\"><b>-1.56</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 평이                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 워낙                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 좋아                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 갔는데                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 거품이                    </font></mark><mark style=\"background-color: hsl(0, 75%, 77%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 심                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 한듯                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ..                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 개연성도                    </font></mark><mark style=\"background-color: hsl(0, 75%, 85%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 엉망                    </font></mark><mark style=\"background-color: hsl(0, 75%, 73%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 에                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 르                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 부                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 아                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 블                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 랑                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 의                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 뜬금없는                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 직                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 관                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>긍정</b></text></td><td><text style=\"padding-right:2em\"><b>긍정 (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>긍정</b></text></td><td><text style=\"padding-right:2em\"><b>1.62</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 너무                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 재미있게                    </font></mark><mark style=\"background-color: hsl(120, 75%, 58%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 봤습니다                    </font></mark><mark style=\"background-color: hsl(120, 75%, 77%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 클래식                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 한                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 추리                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 소설                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 느낌                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 타                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 인기                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 영화                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 때문에                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 개봉                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 관이                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 적어                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 아쉽네요                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #PAD                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #PAD                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>부정</b></text></td><td><text style=\"padding-right:2em\"><b>부정 (0.00)</b></text></td><td><text style=\"padding-right:2em\"><b>긍정</b></text></td><td><text style=\"padding-right:2em\"><b>-1.40</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 아                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 2시간                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 넘게                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 지루하고                    </font></mark><mark style=\"background-color: hsl(0, 75%, 71%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 어이없는                    </font></mark><mark style=\"background-color: hsl(0, 75%, 80%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 추격                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 전과                    </font></mark><mark style=\"background-color: hsl(0, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 의                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 욕이                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 넘쳐                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 과                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 욕                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 으로                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 변한                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 연기                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 게다가                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 예상                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 보다                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 시각화 결과 표 변환\n",
    "\n",
    "visualization.visualize_text(vis_data_records_ig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 읽을 거리\n",
    "\n",
    "- [**Captum**](https://github.com/pytorch/captum) 라이브러리에서 사용한 **_IntegratedGradients_** 기법을 더 자세히 이해하기 위해서는 [**논문**](https://arxiv.org/abs/1703.01365)을 참조해주세요.\n",
    "- 감정 분류와 관련한 더 많은 학습을 원하시는 분들은 Ben Trevett이 작성한 [**pytorch-sentiment-analysis**](https://github.com/bentrevett/pytorch-sentiment-analysis) 튜토리얼을 참조해주세요. (강추)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
